/**
 * Copyright 2013-2015 Axel Huebl, Heiko Burau, Rene Widera, Marco Garten,
 *                     Benjamin Worpitz
 *
 * This file is part of PIConGPU.
 *
 * PIConGPU is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PIConGPU is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with PIConGPU.
 * If not, see <http://www.gnu.org/licenses/>.
 */

namespace picongpu
{
namespace yeeSolver
{
using namespace PMacc;

template<
    typename BlockDescription_,
    typename CurlType_>
struct KernelUpdateE
{
template<
    typename T_Acc,
    typename EBox,
    typename BBox,
    typename Mapping>
ALPAKA_FN_ACC void operator()(
    T_Acc const & acc,
    EBox const & fieldE,
    BBox const & fieldB,
    Mapping const & mapper) const
{
    DataSpace<simDim> const blockIndex(alpaka::idx::getIdx<alpaka::Grid, alpaka::Blocks>(acc));
    DataSpace<simDim> const threadIndex(alpaka::idx::getIdx<alpaka::Block, alpaka::Threads>(acc));

    auto cachedB(CachedBox::create < 0, typename BBox::ValueType > (acc, BlockDescription_()));

    nvidia::functors::Assign assign;
    const DataSpace<simDim> block(mapper.getSuperCellIndex(DataSpace<simDim > (blockIndex)));
    const DataSpace<simDim> blockCell = block * MappingDesc::SuperCellSize::toRT();

    PMACC_AUTO(fieldBBlock, fieldB.shift(blockCell));

    ThreadCollective<BlockDescription_> collective(threadIndex);
    collective(
              assign,
              cachedB,
              fieldBBlock
              );

    alpaka::block::sync::syncBlockThreads(acc);

    const float_X c2 = SPEED_OF_LIGHT * SPEED_OF_LIGHT;
    const float_X dt = DELTA_T;

    CurlType_ curl;
    fieldE(blockCell + threadIndex) += curl(cachedB.shift(DataSpace<simDim > (threadIndex))) * c2 * dt;
}
};

template<
    typename BlockDescription_,
    typename CurlType_>
struct KernelUpdateBHalf
{
template<
    typename T_Acc,
    typename EBox,
    typename BBox,
    typename Mapping>
ALPAKA_FN_ACC void operator()(
    T_Acc const & acc,
    BBox const & fieldB,
    EBox const & fieldE,
    Mapping const & mapper) const
{
    DataSpace<simDim> const blockIndex(alpaka::idx::getIdx<alpaka::Grid, alpaka::Blocks>(acc));
    DataSpace<simDim> const threadIndex(alpaka::idx::getIdx<alpaka::Block, alpaka::Threads>(acc));

    auto cachedE(CachedBox::create < 0, typename EBox::ValueType > (acc, BlockDescription_()));

    nvidia::functors::Assign assign;
    const DataSpace<simDim> block(mapper.getSuperCellIndex(DataSpace<simDim > (blockIndex)));
    const DataSpace<simDim> blockCell = block * MappingDesc::SuperCellSize::toRT();

    PMACC_AUTO(fieldEBlock, fieldE.shift(blockCell));

    ThreadCollective<BlockDescription_> collective(threadIndex);
    collective(
              assign,
              cachedE,
              fieldEBlock
              );


    alpaka::block::sync::syncBlockThreads(acc);

    const float_X dt = DELTA_T;

    CurlType_ curl;
    fieldB(blockCell + threadIndex) -= curl(cachedE.shift(threadIndex)) * float_X(0.5) * dt;
}
};
} // yeeSolver

} // picongpu